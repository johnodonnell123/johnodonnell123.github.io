# Scraping, Storing, and Visualizing Oil Well Production Data

**Project description:** This is a high level overview of a larger scale project. In this project I used 2 separate Scrapy Spiders to pull data for ~ 15,000 oil and gas wells in the Williston Basin in North Dakota. One Spider was built to retrieve general information such as the well name, the operator (company), location, and other useful data. The other Spider retreived monthly production data for the life of each of the ~15,000 wells, leaving us with 1.1+ million records. This data was pipelined into a local lightweight relational database (SQLite3) and queries were ran against this database to pull the data into Pandas DataFrames for visualization. I chose to use Plotly to create some interesting high level views and show what is possible with open source tools and some domain knowledge! 

### 1. Suggest hypotheses about the causes of observed phenomena

Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. 


```javascript
<sub>
if (isAwesome){
  return true
}
</sub>
```


### 2. Assess assumptions on which statistical inference will be based

```javascript
if (isAwesome){
  return true
}
```

### 3. Support the selection of appropriate statistical tools and techniques

<img src="images/dummy_thumbnail.jpg?raw=true"/>

### 4. Provide a basis for further data collection through surveys or experiments

Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. 

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).
